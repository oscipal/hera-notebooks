{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1816ae59",
   "metadata": {},
   "source": [
    "### **Using SNAP with ArgoWorkflows**\n",
    "\n",
    "This notebook will show how a simple example of how to use ESA`s SNAP software in a workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e10fe12",
   "metadata": {},
   "source": [
    "**First some imports and global settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6131bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from hera.workflows import  models, script, Artifact, DAG, NoneArchiveStrategy, Workflow, Container\n",
    "from hera.shared import global_config\n",
    "\n",
    "global_config.host = \"https://dev.services.eodc.eu/workflows/\"\n",
    "global_config.namespace = \"<YOUR NAMESPACE>\"\n",
    "global_config.token = \"<YOUR TOKEN>\"\n",
    "global_config.image = \"ghcr.io/eodcgmbh/cluster_image:2025.2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f097b20",
   "metadata": {},
   "source": [
    "**Setting up Volume**\n",
    "\n",
    "We need to set up our the connection to the volume we want to write to. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b42f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs_volume = models.Volume(\n",
    "    name=\"eodc-mount\",\n",
    "    persistent_volume_claim={\"claimName\": \"eodc-nfs-claim\"},\n",
    "    )\n",
    "\n",
    "security_context = {\"runAsUser\": <YOUR UID>,\n",
    "                    \"runAsGroup\": <YOUR GID>}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0a73ae",
   "metadata": {},
   "source": [
    "**Writing scripts**\n",
    "\n",
    "For this example, we will create a simple Land-Water mask for a Sentinel-1 SIG0 image and write the resulting image to our path in the EODC NFS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c513aa03",
   "metadata": {},
   "source": [
    "First, we download the image from the EODC STAC collection, and save the image as an Artifact to pass down to the next steps. We choose a fixed time and spatial extent, but you could also parameterize this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c09166",
   "metadata": {},
   "outputs": [],
   "source": [
    "@script(outputs=Artifact(name=\"tif-image\", path=\"/tmp/input.tif\", archive=NoneArchiveStrategy()))\n",
    "def download_stac_item():\n",
    "    import pystac_client as pc\n",
    "    from urllib.request import urlretrieve\n",
    "\n",
    "    pc_client = pc.Client.open(\"https://stac.eodc.eu/api/v1\")\n",
    "\n",
    "    time_range = \"2024-01-01/2024-01-30\"\n",
    "\n",
    "    search = pc_client.search(\n",
    "        collections=[\"SENTINEL1_SIG0_20M\"],\n",
    "        datetime=time_range,\n",
    "        query={\"Equi7_TileID\": {\"eq\": \"EU020M_E051N018T3\"}},\n",
    "        max_items=1\n",
    "    )\n",
    "\n",
    "    items = search.item_collection()\n",
    "    \n",
    "    url = items[0].assets[\"VH\"].href\n",
    "\n",
    "    urlretrieve(url, \"/tmp/input.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5e20b7",
   "metadata": {},
   "source": [
    "Next, we need to get the xml to tell SNAP how to do the processing. You can get the xml from the SNAP software by creating a processing graph and exporting the graph as an xml. When copying the xml you need to make sure to adjust the input and output path accordingly. The xml will also be saved as an Artifact to be passed down to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0023516",
   "metadata": {},
   "outputs": [],
   "source": [
    "@script(outputs=Artifact(name=\"processing-graph\", path=\"/tmp/processing_graph.xml\", archive=NoneArchiveStrategy()))\n",
    "def snap_graph():\n",
    "    output_path = \"/eodc/private/tempearth/masked/LW_masked.tif\"\n",
    "    input_artifact = \"/tmp/input.tif\"\n",
    "\n",
    "    xml = f\"\"\"\n",
    "                <graph id=\"Graph\">\n",
    "                <version>1.0</version>\n",
    "                <node id=\"Read\">\n",
    "                <operator>Read</operator>\n",
    "                <sources/>\n",
    "                <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
    "                <useAdvancedOptions>true</useAdvancedOptions>\n",
    "                <file>{input_artifact}</file>\n",
    "                <copyMetadata>true</copyMetadata>\n",
    "                <bandNames/>\n",
    "                <pixelRegion>0,0,15000,15000</pixelRegion>\n",
    "                <maskNames/>\n",
    "                </parameters>\n",
    "                </node>\n",
    "                <node id=\"LandWaterMask\">\n",
    "                <operator>LandWaterMask</operator>\n",
    "                <sources>\n",
    "                <sourceProduct refid=\"Read\"/>\n",
    "                </sources>\n",
    "                <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
    "                <resolution>50</resolution>\n",
    "                <subSamplingFactorX>1</subSamplingFactorX>\n",
    "                <subSamplingFactorY>1</subSamplingFactorY>\n",
    "                </parameters>\n",
    "                </node>\n",
    "                <node id=\"Write\">\n",
    "                <operator>Write</operator>\n",
    "                <sources>\n",
    "                <sourceProduct refid=\"LandWaterMask\"/>\n",
    "                </sources>\n",
    "                <parameters class=\"com.bc.ceres.binding.dom.XppDomElement\">\n",
    "                <file>{output_path}</file>\n",
    "                <formatName>GeoTIFF</formatName>\n",
    "                </parameters>\n",
    "                </node>\n",
    "                <applicationData id=\"Presentation\">\n",
    "                <Description/>\n",
    "                <node id=\"Read\">\n",
    "                <displayPosition x=\"89.0\" y=\"174.0\"/>\n",
    "                </node>\n",
    "                <node id=\"LandWaterMask\">\n",
    "                <displayPosition x=\"224.0\" y=\"191.0\"/>\n",
    "                </node>\n",
    "                <node id=\"Write\">\n",
    "                <displayPosition x=\"455.0\" y=\"135.0\"/>\n",
    "                </node>\n",
    "                </applicationData>\n",
    "                </graph>\n",
    "                \"\"\"\n",
    "    \n",
    "    with open(\"/tmp/processing_graph.xml\", \"w\") as f:\n",
    "        f.write(xml)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52933c0",
   "metadata": {},
   "source": [
    "Finally, we can do the SNAP processing. The [image](https://github.com/oscipal/snap_image) given here has SNAP v12 installed, you can also create your own image, just beware that SNAP needs to be able to write an auxillary data when running for the first time. In this image the path to the auxData is set to go to the EODC NFS, if you don't have read access to the folder in line 19 of the dockerfile, you need to adjust your image accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36822cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "snap_processing = Container(\n",
    "    name=\"snap-processing\",\n",
    "    image=\"ghcr.io/oscipal/snap_image\",\n",
    "    command=[\"gpt\"],\n",
    "    args=[\"/tmp/processing_graph.xml\"],\n",
    "    inputs=[Artifact(name=\"tif-image\", path=\"/tmp/input.tif\"),\n",
    "            Artifact(name=\"processing-graph\", path=\"/tmp/processing_graph.xml\")],\n",
    "    volume_mounts=[models.VolumeMount(name=\"eodc-mount\", mount_path=\"/eodc\")],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec02fe8",
   "metadata": {},
   "source": [
    "**Creating the Workflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57448f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Workflow(\n",
    "    generate_name=\"snap-processing-\",\n",
    "    volumes = [nfs_volume],\n",
    "    security_context=security_context,\n",
    "    entrypoint=\"workflow\"\n",
    ") as w:\n",
    "    with DAG(name=\"workflow\"):\n",
    "        step1 = download_stac_item()\n",
    "        step2 = snap_graph()\n",
    "        step3 = snap_processing(arguments=[step1.get_artifact(\"tif-image\").with_name(\"tif-image\"),\n",
    "                                           step2.get_artifact(\"processing-graph\").with_name(\"processing-graph\")])\n",
    "        \n",
    "        step1 >> step2 >> step3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b74572",
   "metadata": {},
   "source": [
    "**Submitting the Workflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4667834",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.create()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zarr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
