{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf0530b6",
   "metadata": {},
   "source": [
    "### **Connecting to the EODC Dask**\n",
    "\n",
    "This notebook will show how to connect to the EODC Dask in ArgoWorkflows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e90c5a6",
   "metadata": {},
   "source": [
    "**First some imports and global settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2588f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hera.workflows import script, Parameter, DAG, Workflow\n",
    "from hera.shared import global_config\n",
    "\n",
    "global_config.host = \"https://services.eodc.eu/workflows/\"\n",
    "global_config.namespace = \"<YOUR NAMESPACE>\"\n",
    "global_config.token = \"<YOUR TOKEN>\"\n",
    "global_config.image = \"ghcr.io/eodcgmbh/cluster_image:2025.2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7b2d22",
   "metadata": {},
   "source": [
    "**Writing scripts**\n",
    "\n",
    "As the EODC Dask is running on the same cluster as ArgoWorkflows connecting to it works easily by setting the `address` and `proxy_address`. The image specified in `cluster_options.image` has to be the same as the one used for running the script. In a first step we can initialize the cluster and use it in a second step. To make sure we shut down the cluster at the end we need a final step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a701230",
   "metadata": {},
   "outputs": [],
   "source": [
    "@script()\n",
    "def initialize_dask():\n",
    "    from dask_gateway import Gateway\n",
    "\n",
    "    # Connect to the Gateway\n",
    "    gateway = Gateway(\n",
    "        address=\"http://traefik-dask-gateway-internal.dask-gateway.svc.cluster.local\",\n",
    "        proxy_address=\"tcp://traefik-dask-gateway-internal.dask-gateway.svc.cluster.local:80\")\n",
    "    \n",
    "    # Define cluster options\n",
    "    cluster_options = gateway.cluster_options()\n",
    "\n",
    "    # Set the number of cores per worker\n",
    "    cluster_options.worker_cores = 8\n",
    "\n",
    "    # Set the memory per worker (in GB)\n",
    "    cluster_options.worker_memory = 16\n",
    "\n",
    "    # Specify the Docker image to use for the workers\n",
    "    cluster_options.image = \"ghcr.io/eodcgmbh/cluster_image:2025.2.0\"\n",
    "\n",
    "    # Create a new cluster with the specified options\n",
    "    cluster = gateway.new_cluster(cluster_options)\n",
    "\n",
    "    # Automatically scale the cluster between 1 and 10 workers based on workload\n",
    "    cluster.adapt(1, 10)  \n",
    "\n",
    "    # Optionally, scale the cluster to use only one worker\n",
    "    # cluster.scale(1)\n",
    "\n",
    "    # Get a Dask client for the cluster\n",
    "    client = cluster.get_client()\n",
    "\n",
    "    print(cluster.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e82ba35",
   "metadata": {},
   "outputs": [],
   "source": [
    "@script()\n",
    "def use_dask(cluster_name):\n",
    "    from dask_gateway import Gateway\n",
    "    gateway = Gateway(\n",
    "            address=\"http://traefik-dask-gateway-internal.dask-gateway.svc.cluster.local\",\n",
    "            proxy_address=\"tcp://traefik-dask-gateway-internal.dask-gateway.svc.cluster.local:80\"\n",
    "        )\n",
    "    cluster = gateway.connect(cluster_name)\n",
    "    client = cluster.get_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b07abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "@script()\n",
    "def shutdown_cluster():\n",
    "    from dask_gateway import Gateway\n",
    "    gateway = Gateway(\n",
    "            address=\"http://traefik-dask-gateway-internal.dask-gateway.svc.cluster.local\",\n",
    "            proxy_address=\"tcp://traefik-dask-gateway-internal.dask-gateway.svc.cluster.local:80\"\n",
    "        )\n",
    "    \n",
    "    if gateway.list_clusters():\n",
    "        cluster = gateway.connect(gateway.list_clusters()[0].name)\n",
    "        cluster.shutdown()\n",
    "\n",
    "    else:\n",
    "        print(\"No running clusters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2349d9ff",
   "metadata": {},
   "source": [
    "**Creating the Workflow**\n",
    "\n",
    "For the workflow we need to make sure the cluster shuts down properly after use. To do this, we can define a DAG which will run on exit regardless of if our main workflow is successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc40316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Workflow(\n",
    "    generate_name=\"using-dask-\",\n",
    "    entrypoint=\"workflow\",\n",
    "    on_exit=\"shutdown\"\n",
    ") as w:\n",
    "\n",
    "    with DAG(name=\"workflow\"):\n",
    "        init = initialize_dask()\n",
    "        use = use_dask(arguments={\"cluster_name\": init.result})\n",
    "\n",
    "        init >> use\n",
    "\n",
    "    with DAG(name=\"shutdown\"):\n",
    "        shutdown_cluster()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde87b64",
   "metadata": {},
   "source": [
    "**Submitting the Workflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4c799d",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.create()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zarr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
